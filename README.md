# 3. Tracabilité du vivant  
(GPS, GSM, CAMERA, Information Gathering)

## a. Tracabilité en temps réel des etres humains par camera et traitement d'image
Le traitement d'images est un domaine très important et actif dans la recherche en informatique. La baisse des coûts et la qualité croissante des caméras ont permis un suivi statique et dynamique des objets. Les humains sont évidemment l’un des objets les plus importants mais aussi les plus difficiles à suivre visuellement. De nombreux systèmes de sécurité sont simplement un réseau de caméras surveillé par un petit groupe d'humains, mais quelque, comme le système de vidéosurveillance chinois, utilisent la technologie de trait du visage pour identifier et suivre chaque personne devant une caméra. [Source](https://www.bbc.co.uk/news/world-asia-china-43751276)  
Le concept le plus fondamental de la détection d'objet provient de l'utilisation de dérivés d'image. Essentiellement, la façon la plus simple de détecter la présence d’un objet dans une photo est de détecter l’absence d’un fond continu. Il y aura une transition du fond de l'objet le long des bords de l'objet. Une image numérique est composée d'une valeur de luminosité ainsi que d'autres valeurs de couleur. À partir de là, nous contrastons les valeurs de luminosité par rapport à ses voisins. Ensuite, en fonction de la différence entre la luminosité des pixels, vous pouvez détecter les bords d'un objet. [Source](https://mccormickml.com/2013/02/26/image-derivative/)  
Même pour ce concept de base, les méthodes pour obtenir et manipuler ces dérivés varient grandement. Certaines équations ont des usages différents pour les voisins verticaux, horizontaux et diagonaux. Ils peuvent utiliser différentes méthodes de pondération pour les dérivées partielles, telles que l'opérateur de Prewitt ou l'opérateur Sobel, qui sont toutes les deux des méthodes de mappage 3x3 pixels avec des différentes pondérations pour les voisins non-diagonaux. Une filtration supplémentaire peut utiliser un gradient de secondes dérivées, ou une limite du contraste d’un pixel avec ses voisins pour mieux analyser l’image. [Source](https://www.cs.toronto.edu/~mangas/teaching/320/slides/CSC320L05.pdf)  
Pour détecter des objets en mouvement, une approche plus complexe est nécessaire pour le suivi en temps réel. Les environnements réalistes n'ont pas la nature idéale d'un objet avec un fond et les techniques de dérivée d'image décrites précédemment ne fonctionnent pas bien pour analyser une seule image dans ce contexte. Cependant, ça peut être utilisé pour contraster la différence entre deux images consécutives, pour créer un contour de bord dynamique. Ça fonctionne assez bien pour les caméras statiques analysant l'activité d'un lieu particulier.  
Mais des applications plus complexes, telles que les caméras sur une voiture autonome, nécessitent encore une fois un filtrage supplémentaire. La compensation d’egomotion est utilisée pour contrecarrer le déplacement de la caméra entre les images en appliquant une couche supplémentaire de détection de contraste. En effectuant un zoom arrière sur la détection pixel par pixel pour une détection zone par zone, les zones étant des tas de pixels, de petites variations peuvent être atténuées. En fonction de la luminosité de chaque zone pour chaque image, il est possible de faire correspondre les différentes zones entre les deux images en fonction de leur luminosité. Ça aide à prendre en compte les petits ajustements de la caméra. [Source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4121190/)  
Un autre système de filtration utilisé est appelé histogramme des gradients orientés (HOG). Cette technique consiste essentiellement à calculer la direction et la magnitude des dérivées partielles de chaque pixel, puis à utiliser la fréquence des orientations pour mapper la forme de chaque zone. C’est utile parce qu’il donne plus d’informations sur la direction et la force de la forme d’une image que les dérivées de l’image mentionnées précédemment. Les comparaisons de zones peuvent ensuite être utilisées pour suivre les mouvements d’une personne dans le temps. Empiriquement, ce s'est avéré utile pour les humains, parce que les défauts de cette approche sont masqués par la faible fréquence de rotation ou de flexion de la posture par les personnes en mouvement. [Source](https://www.learnopencv.com/histogram-of-oriented-gradients/)  
Enfin, la trait du visage peut être utilisée pour faire passer de l’existence d’une personne à son identité. La première partie de ce processus consiste à mapper des zones aux traits du visage. Un simple rectangle, ou une forme plus complexe, peut être associé à un trait du visage en fonction du contraste entre les pixels de la zone et la forme des bords. Le chevauchement entre les zones peut également être utilisé pour une analyse plus approfondie. Différents algorithmes peuvent être utilisés pour ça. [Source](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf)  
L'autre aspect, et peut-être le plus important, des techniques de trait du visage concerne le domaine de l'apprentissage automatique. Les visages présentent de nombreuses variations de forme, ainsi que des images variables avec l’échelle, la pose et l’illumination. Alors, ces méthodes composées pour détecter les visages sont également couplées à des ensembles de données de cas de test pour créer et d’entraîner un modèle mathématique plus adapté à la détection précise d’un visage dans des conditions non-idéales. Ça peut-être constamment améliorées en introduisant plus de données de test pour que le modèle puisse apprendre.
 
## b. Tracabilité en temps réel par gps
Le suivi en temps réel à l'aide du GPS est également très important pour la technologie d'aujourd'hui et de l’avenir. Pratiquement tous les téléphones sont équipés d’un GPS qui permet une localisation précise à quelques mètres de distance grâce aux améliorations récentes de la technologie. Des applications telles que Waze l'utilisent pour détecter de grands tas de voitures et de prédire avec plus de précision les temps de voyage. Les voitures autonomes auront également un suivi de localisation GPS et seront capables de distinguer les voitures autonomes des voitures conduites par l'homme.  
Le suivi GPS fonctionne sur un grand réseau de satellites. Chaque satellite connaît sa propre position et diffuse en permanence sa position et son temps en utilisant des ondes radio. Comme la vitesse de ces ondes est constante, un récepteur GPS peut déterminer la distance qui sépare chaque satellite de lui-même en fonction du temps de parcours de l’onde. Cette distance est unidimensionnelle, mais en utilisant plusieurs satellites, le récepteur peut ensuite déterminer la distance de chaque satellite en trois dimensions.  
Cependant, le récepteur doit calculer une autre dimension: le temps. Lorsqu'un récepteur reçoit une onde radio avec la position et l'heure d'un satellite, une hypothèse formulait concernant la synchronisation des heures. S'il existe une différence de temps entre le satellite et le récepteur à un instant donné, le temps de parcours calculé pour l'onde radio est incorrect, et donc sa distance. Un quatrième satellite est nécessaire pour calculer le décalage horaire, et des satellites supplémentaires sont souvent utilisés pour d’autres mesures de correction des erreurs / retards géographiques. [Source](http://webarchiv.ethz.ch/geometh-data/downloads/GPSBasics_en.pdf)  
Le GPS peut également être assisté par l’utilisation de réseaux Wi-Fi. Lorsqu'un appareil avec des capacités GPS et Wi-Fi utilise le GPS pour déterminer sa location, il peut également enregistrer les signaux Wi-Fi à proximité et leur puissance. Ensuite, lorsqu’il est à proximité sans disposer d’une connectivité GPS élevée, par exemple à l’intérieur, il pourra compter sur la détection des signaux Wi-Fi à proximité et sur la position approximative. Cette position peut être rendu plus précis en utilisant plusieurs appareils qui suivent les signaux Wi-Fi et utilisent ce service en tandem avec des signaux GPS plus puissants. [Source](https://www.lifewire.com/wifi-positioning-system-1683343)
 
## c. Tracabilité par croisement de l'information
La combinaison de ces deux domaines n'a pas été étudiée autant que les deux sujets individuels. Une partie du problème est liée à la vie privée, parce qu’avoir la capacité de suivre une personne quand elle est à la caméra et hors de la caméra est inconfortable pour beaucoup de gens. Il existe également la redondance entre les deux technologies. Mais, comme la manière que le Wi-Fi peut aider le GPS et inversement, le traitement d'images et le GPS peuvent fonctionner ensemble.  
La réception en profondeur est une des principales faiblesses du traitement des images. Il existe de nombreux modèles précis pour la réception en profondeur, utilisant des techniques similaires à l'histogramme mentionné précédemment pour l'analyse des caractéristiques et des formes d'une image. Cependant, ces modèles nécessitent l’apprentissage en utilisant des données de test, de la même manière que les techniques de trait du visage. Des technologies supplémentaires, telles que l’utilisation de la technologie RF pour mesurer la distance en utilisant des ondes radio, ou le GPS si l’objet en question la possède, sont souvent utilisées en tandem. [Source](www.cs.cornell.edu/~asaxena/learningdepth/ijcv_monocular3dreconstruction.pdf)  
Un exemple de cette assistance peut être trouvé dans les intervenants médicaux naviguant sur un système routier. Un système GPS peut être installé sur chaque ambulance, permettant à un centre médical de suivre leur position. Ensuite, lorsqu'un appel EMS est traité et sa location est enregistré, le centre peut envoyer l'ambulance la plus proche. Puis, chaque feu peut utiliser le traitement d’image pour détecter la présence d’une ambulance et changer le feu en conséquence pour permettre une traversée plus rapide. C’est assisté aussi par GPS permettant un suivi plus précis de la distance d’une ambulance par rapport à un feu. [Source](http://airccse.org/journal/jcsit/5413ijcsit10.pdf)  
Le suivi des objets masqués dans des scénarios multi-objets est aussi dur pour le traitement des images. Le GPS seul ne convient pas toujours à ces applications, parce qu’un objet obscurci est généralement petit et il est souhaitable de le suivre avec une précision de quelques centimètres, pas de quelques mètres. Les techniques de traitement d'image décrites précédemment permettent de suivre avec précision l'objet pendant les périodes de visibilité lors d'un enregistrement vidéo, puis d'utiliser le GPS pour déduire une position plus précise de l'objet pendant la période d'obscurité. Il existe des méthodes pour le faire pendant l'obscurité et immédiatement après l'obscurité.  
Un autre exemple est pour les sports. Plus précisément, avec le football, il est très difficile de suivre en même temps 22 joueurs et leurs mouvements avec une seule caméra. Cependant, en raison de la taille du champ, même l’installation de plusieurs caméras souffrira d’erreurs de réception en profondeur de plus en plus éloignées. Alors, en équipant chaque joueur d'un GPS et en configurant le système de caméra à lire ces images, il est possible de faire correspondre un joueur à l'écran à un GPS. Puis, ils peuvent utiliser le GPS pour la correction de zone sur de grandes distances, parallèlement à des perspectives obscurcies. [Source](https://www.mdpi.com/2220-9964/4/3/1317/pdf)

# 7. Projet Application Mobile de Triangulation par Wifi
## a. Introduction
Comme mentionné dans la [section 3](#3-tracabilité-du-vivant), Wi-Fi et GPS peuvent être couplés afin de permettre une estimation plus précise de la localisation. Nous voulions tester avec quelle précision ces deux systèmes de localisation pouvaient collaborer ou, plus précisément, se remplacer. Lorsqu'un appareil a accès au Wi-Fi et au GPS, par exemple à l'extérieur en milieu urbain, il peut localiser les signaux Wi-Fi par rapport au signal GPS. Ensuite, lorsque cet appareil se trouve dans une zone où le signal GPS n'est pas puissant, par exemple à l'intérieur, il peut s'appuyer sur une estimation du signal à l'aide des signaux Wi-Fi à proximité et des données précédemment collectées. En raison de la taille de sa base d'utilisateurs, Google dispose d'une vaste base de données de localisations de signaux Wi-Fi, mais nous voulions voir si nous pouvions reproduire ça à l'aide de notre téléphone et de tests locaux.  
Tous les membres du groupe ayant un téléphone Android, cette expérience a été réalisée à l'aide d'une application Android. Plus précisément, cette application a été développée et testée sur un Samsung Galaxy S5 à l’aide de l’API 23 (version 6.0.1). L'application a été développée avec Kotlin et utilise l'architecture de base de données Room intégrée pour enregistrer les données localement. Il utilise également la [bibliothèque AirLocation](https://github.com/mumayank/AirLocation) afin d’acquérir la location actuel à l’aide du système GPS intégré au téléphone, l'équation [à partir de ce site Web](https://www.movable-type.co.uk/scripts/latlong.html) pour calculer la distance entre la location actuel et la location estimé, et l'équation [de Stack Overflow](https://stackoverflow.com/a/18359639) pour calculer la distance des signaux Wi-Fi. Cette application a été testée à l'aide de données de localisation du campus Benjamin Franklin et de la Résidence du Parc.

## b. Explication
Le principe de cette application consiste à estimer la location actuelle à l'aide de nos propres algorithmes et à le comparer à la location actuel. Pour le faire, nous créons une base de données contenant les informations collectées à partir des analyses Wi-Fi. En utilisant ces analyses, nous pouvons noter l'identifiant, la force du signal et la fréquence de chaque réseau à proximité, ainsi que notre position actuelle. Une remarque est que chaque réseau peut contenir plusieurs signaux avec le même SSID (par exemple, eduroam) mais contiendra chacun un BSSID unique que nous pouvons enregistrer et référencer. Nous pouvons enregistrer en permanence ces signaux lorsque nous parcourons le campus, obtenant suffisamment de données pour déterminer la location de chaque signal.  
Puis, nous avons essayé différents algorithmes pour déterminer notre location. Le premier consistait à choisir la location du signal le plus proche. La distance entre un périphérique et un signal est basée sur l’intensité et la fréquence du signal, parce que l'intensité est basée sur la fréquence et la distance du signal. FSPL est une prédiction de la force du signal RF à une distance donnée. Il s'agit de l'intensité donnée par WifiManager d'Android et de la force représentée par les 4 barres d'un signal. Cette valeur est logarithmique et va en fait de 0 à -100, et la gamme de 4 à 0 n'est qu'un mécanisme de simplification utilisé par votre gestionnaire Wi-Fi Manager. [Source](https://www.everythingrf.com/rf-calculators/free-space-path-loss-calculator)  
Nous avons donc estimé la location de chaque signal en fonction de la location où nous nous trouvions lorsque le signal était le plus proche, puis nous avons sélectionné le signal le plus proche de nous et utiliser sa location (ou l'endroit le plus proche que nous avons enregistré) comme notre location. Nous pouvons ensuite comparer en utilisant la formule de Haversine, ce qui est un peu excessif car les considérations qu’il prend en compte pour la nature sphérique de la Terre sont négligeables face à des distances aussi courtes, mais il est convenu qu’elles sont précises. Les résultats sont bons parce que, même si nous n'utilisons qu'un seul point de données, nous collections beaucoup de données pour nous assurer que ce point de données est très précis. [Source](https://community.esri.com/groups/coordinate-reference-systems/blog/2017/10/05/haversine-formula)

## c. Algorithmes de peu de données
Si vous apportez des simplifications, telles que le traitement des localisations comme un plan bidimensionnel en raison de leur proximité, vous pouvez réellement mettre en œuvre un système moyennement complexe mais facile à comprendre utilisant seulement quelques points de données. Je vais expliquer ce système et relier tous les concepts mathématiques utilisés plus complexes que les opérations linéaires et trigonométriques de base.  
Premièrement, si nous obtenons les locations des deux signaux A et B de notre base de données, ainsi que leur distance par rapport à notre location L, [nous pouvons créer des équations pour deux cercles](https://www.purplemath.com/modules/sqrcircle.htm) en utilisant les signaux comme centre et le rayon comme distance de L. Puis, [nous pouvons calculer les deux points d’intersection de ces cercles](https://www.analyzemath.com/CircleEq/circle_intersection.html), autrement connu comme les deux locations que L pourrait être. Nous avons en fait besoin d’un troisième point C connu pour déterminer lequel de ces deux points est réellement L en utilisant la même méthode. Vous devez créer la ligne AB et vérifier que C n’est pas dessus, sinon cela ne fonctionnera pas (par exemple, les trois points doivent former un triangle. Ensuite, nous connaissons enfin notre position.  
Nous pouvons également le faire en utilisant seulement deux points et un peu plus de trigonométrie. Nous pouvons utiliser la ligne créée AB et déterminer la pente réciproque négative d'une droite perpendiculaire en intersection entre L et le point d'intersection indéterminé O. Nous pouvons ensuite utiliser le [théorème de la bissectrice d'angle](https://en.wikipedia.org/wiki/Angle_bisector_theorem) afin de déterminer la longueur de AO et de BO, et ainsi déterminer où O se trouve le long de la ligne AB.  
Ensuite, nous pouvons calculer les angles des deux triangles à angle droit LO créés à l'aide de cosinus, puis utiliser [cette formule de triangulation](https://en.wikipedia.org/wiki/Triangulation_\(surveying\)#Distance_to_a_point_by_measuring_two_fixed_angles) pour calculer la longueur de LO. Maintenant, nous connaissons la location de O, l'équation de LO et la longueur de LO, ce qui signifie que nous pouvons trouver la location de L.  
Il existe probablement davantage de variantes de ce phénomène, mais voici quelques exemples de moyens de base pour trouver votre position lorsque vous supposez que la Terre est un plan plat. De toute évidence, il y a encore du travail à faire, car vous devez déterminer la position exacte de ces signaux (que nous avons approximés) et tenir compte de la courbure de la Terre (que nous avons ignorées), et nous avons supposé que nous ne bougions pas. nous sommes souvent en train de mesurer). C'est pourquoi Google et d'autres sociétés utilisent des algorithmes beaucoup plus sophistiqués utilisant les données des utilisateurs afin de prédire votre position à l'aide de la localisation Wi-Fi.